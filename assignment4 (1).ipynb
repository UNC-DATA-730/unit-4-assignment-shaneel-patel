{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0d234f-1e1a-4495-8208-e177e7f527aa",
   "metadata": {},
   "source": [
    "Complete the exercises below For **Assignment #4**.\n",
    "\n",
    "Use **Markdown** cells for the non-code answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f720a0-2ead-44f5-bc11-8cbefda7b7d4",
   "metadata": {},
   "source": [
    "In this assignment we will work with the data underlying the *FiveThirtyEight* article [\"Higher Rates Of Hate Crimes Are Tied To Income Inequality\"](https://fivethirtyeight.com/features/higher-rates-of-hate-crimes-are-tied-to-income-inequality/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3788bf-60c0-4b04-a09e-29bb08002d83",
   "metadata": {},
   "source": [
    "Load the `tidymodels`, `readr`, and `moderndive` packages in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c363d814-19a6-4173-899e-c54ada1860d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(c(\"tidymodels\", \"readr\", \"moderndive\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4064cbe-78bd-4549-8543-fd91ed775e6e",
   "metadata": {},
   "source": [
    "We can read the data from a **CSV file** at the following URL: [http://bit.ly/2ItxYg3](http://bit.ly/2ItxYg3).\n",
    "\n",
    "Use the `read_csv` function to read the data into our R session. Call the new table `hate_crimes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94ce1201-dd72-4109-9a64-333b7286aac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in read_csv(\"hate_crimes.csv\"): could not find function \"read_csv\"\n",
     "output_type": "error",
     "traceback": [
      "Error in read_csv(\"hate_crimes.csv\"): could not find function \"read_csv\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "hate_crimes <- read_csv(\"hate_crimes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4806491-e256-4823-aa63-612157c25966",
   "metadata": {},
   "source": [
    "Next, letâ€™s add the high-school degree variable into the mix by creating a scatterplot showing:\n",
    "\n",
    "- Income on the y-axis (this is the `income` variable)\n",
    "- Percent of adults 25 or older with a high school degree on the x-axis (this is the `hs` variable)\n",
    "- The points colored by level of urbanization in a region (this is the variable `urbanization`)\n",
    "\n",
    "\n",
    "**In addition, add a line of best fit (regression line) for each level of the variable urbanization (one for â€œlowâ€, one for â€œhighâ€).**\n",
    "\n",
    "*Add the regression lines to the plot using the `geom_parallel_slopes` function from the `moderndive` package. This function will draw the regression lines based on fitting a regression model with parallel slopes (i.e., with no interaction between `hs` and `urbanization`).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df52489-dc41-4d74-ba64-a93f1d5c7ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "â€œYour system is mis-configured: â€˜/var/db/timezone/localtimeâ€™ is not a symlinkâ€\n",
      "Warning message:\n",
      "â€œâ€˜/var/db/timezone/localtimeâ€™ is not identical to any known timezone fileâ€\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: object 'hate_crimes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'hate_crimes' not found\nTraceback:\n",
      "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'hate_crimes' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "library(moderndive)\n",
    "\n",
    "ggplot(hate_crimes, aes(x = hs, y = income, color = urbanization)) +\n",
    "  geom_point() +\n",
    "  geom_parallel_slopes(aes(group = urbanization)) +\n",
    "  labs(\n",
    "    title = \"Income vs. High School Degree Percentage\",\n",
    "    x = \"Percent of Adults 25+ with a High School Degree\",\n",
    "    y = \"Income\",\n",
    "    color = \"Urbanization Level\"\n",
    "  ) +\n",
    "  theme_minimal()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e532f1d-fa73-402b-96e0-f104a4c02791",
   "metadata": {},
   "source": [
    "â“Which regression line (high urbanization or low urbanization) appears to have the larger intercept?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61301467-8beb-4ae7-9019-7965ba70ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Low urbanization has the larger intercept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c51941-740b-4bba-975f-12083a90dda0",
   "metadata": {},
   "source": [
    "Now letâ€™s create a second scatterplot using the same variables, but this time draw the regression lines using `geom_smooth(method = \"lm\")`, which will allow for separate, non-parallel slopes for each urbanization group. \n",
    "\n",
    "**Code your scatter plot in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbdf3299-5151-4963-addb-6089506a9b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'hate_crimes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'hate_crimes' not found\nTraceback:\n",
      "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'hate_crimes' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "ggplot(hate_crimes, aes(x = hs, y = income, color = urbanization)) +\n",
    "  geom_point() +\n",
    "  geom_smooth(method = \"lm\", se = FALSE) +\n",
    "  labs(\n",
    "    title = \"Income vs. High School Degree Percentage\",\n",
    "    x = \"Percent of Adults 25+ with a High School Degree\",\n",
    "    y = \"Income\",\n",
    "    color = \"Urbanization Level\"\n",
    "  ) +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b4ef0-c250-4f50-8354-75075608b95c",
   "metadata": {},
   "source": [
    "â“Based on visually comparing the two models shown above, do you think it would be best to run a â€œparallel slopesâ€ model (i.e. a model that estimates one shared slope for the two levels of urbanization), or a more complex â€œinteraction modelâ€ (i.e. a model that estimates a separate slope for the two levels of urbanization)?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f4b05e-c7cc-4486-916c-1ddda83e34ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#It would be best to run a more complex interaction model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b774c5-d4d1-4473-be77-4a1271fa4ca2",
   "metadata": {},
   "source": [
    "Fit the following two regression models that examine the relationship between household `income` (as response variable), and high-school education (`hs`) and `urbanization` as explanatory variables:\n",
    "\n",
    "1. A parallel slopes model (i.e., no interaction between `hs` and `urbanization`). â—ï¸Save the data recipe and model under the variables `ps_rec` and `ps_mod`, respectively. \n",
    "1. A non-parallel slopes model (i.e., allow `hs` and `urbanization` to interact in your model). â—ï¸Save the data recipe and model under the variable: `nps_rec` and `nps_mod`, respectively.\n",
    "\n",
    "**Code you your models in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30523b47-a9af-4462-9c47-8bab30e76cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'hate_crimes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'hate_crimes' not found\nTraceback:\n",
      "1. step_dummy(step_naomit(recipe(income ~ hs + urbanization, data = hate_crimes), \n .     everything()), urbanization)",
      "2. add_step(recipe, step_dummy_new(terms = enquos(...), role = role, \n .     trained = trained, one_hot = one_hot, contrasts = contrasts, \n .     preserve = keep_original_cols, naming = naming, levels = levels, \n .     sparse = sparse, keep_original_cols = keep_original_cols, \n .     skip = skip, id = id))",
      "3. step_naomit(recipe(income ~ hs + urbanization, data = hate_crimes), \n .     everything())",
      "4. add_step(recipe, step_naomit_new(terms = enquos(...), role = role, \n .     trained = trained, columns = columns, skip = skip, id = id))",
      "5. recipe(income ~ hs + urbanization, data = hate_crimes)",
      "6. recipe.formula(income ~ hs + urbanization, data = hate_crimes)",
      "7. rlang::is_missing(data)",
      "8. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'hate_crimes' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "# parallel slopes model\n",
    "\n",
    "ps_rec = recipe(income ~ hs + urbanization, data = hate_crimes) |> \n",
    "    step_naomit(everything()) |>   # remove missing values\n",
    "    step_dummy(urbanization) |>    # dummy encode the urbanization variable\n",
    "    prep()                         # run the recipe on the training data provided\n",
    "\n",
    "mod = linear_reg() |> set_engine('lm')\n",
    "\n",
    "ps_mod = mod |> fit(income ~ ., juice(ps_rec))\n",
    "\n",
    "ps_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f00c972-f677-4315-8ef8-a85c6e18be95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â”€â”€ \u001b[1mAttaching packages\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels 1.3.0 â”€â”€\n",
      "\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.8     \u001b[32mâœ”\u001b[39m \u001b[34mrsample     \u001b[39m 1.3.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mdials       \u001b[39m 1.4.0     \u001b[32mâœ”\u001b[39m \u001b[34mtibble      \u001b[39m 3.2.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mdplyr       \u001b[39m 1.1.4     \u001b[32mâœ”\u001b[39m \u001b[34mtidyr       \u001b[39m 1.3.1\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34minfer       \u001b[39m 1.0.8     \u001b[32mâœ”\u001b[39m \u001b[34mtune        \u001b[39m 1.3.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.4.0     \u001b[32mâœ”\u001b[39m \u001b[34mworkflows   \u001b[39m 1.2.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mparsnip     \u001b[39m 1.3.1     \u001b[32mâœ”\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.1.0\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mpurrr       \u001b[39m 1.0.4     \u001b[32mâœ”\u001b[39m \u001b[34myardstick   \u001b[39m 1.3.2\n",
      "\u001b[32mâœ”\u001b[39m \u001b[34mrecipes     \u001b[39m 1.3.1     \n",
      "\n",
      "â”€â”€ \u001b[1mConflicts\u001b[22m â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidymodels_conflicts() â”€â”€\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mscales\u001b[39m::discard()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31mâœ–\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m  masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: object 'hate_crimes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'hate_crimes' not found\nTraceback:\n",
      "1. step_normalize(., all_predictors())",
      "2. add_step(recipe, step_normalize_new(terms = enquos(...), role = role, \n .     trained = trained, means = means, sds = sds, na_rm = na_rm, \n .     skip = skip, id = id, case_weights = NULL))",
      "3. recipe(income ~ hs + urbanization, data = hate_crimes)",
      "4. recipe.formula(income ~ hs + urbanization, data = hate_crimes)",
      "5. rlang::is_missing(data)",
      "6. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'hate_crimes' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "library(tidymodels)\n",
    "ps_rec <- recipe(income ~ hs + urbanization, data = hate_crimes) %>%\n",
    "  step_normalize(all_predictors())\n",
    "\n",
    "ps_mod <- linear_reg() %>%\n",
    "  set_engine(\"lm\") %>%\n",
    "  fit(income ~ hs + urbanization, data = hate_crimes)\n",
    "\n",
    "nps_rec <- recipe(income ~ hs * urbanization, data = hate_crimes) %>%\n",
    "  step_normalize(all_predictors())\n",
    "\n",
    "nps_mod <- linear_reg() %>%\n",
    "  set_engine(\"lm\") %>%\n",
    "  fit(income ~ hs * urbanization, data = hate_crimes)\n",
    "\n",
    "tidy(ps_mod)\n",
    "tidy(nps_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f615c-c5b3-4246-8460-1cd85c06c43a",
   "metadata": {},
   "source": [
    "The following code creates a table of your model predictions over the training data. Calculate the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) (R<sup>2</sup>) for each model:\n",
    "\n",
    "```r\n",
    "rbind(\n",
    "    augment(ps_mod, juice(ps_rec)) |> select(income, .pred, .resid) |> mutate(model = \"parallel_slopes\"),\n",
    "    augment(nps_mod, juice(nps_rec)) |> select(income, .pred, .resid) |> mutate(model = \"interaction\")\n",
    ")\n",
    "```\n",
    "\n",
    "1. Group rows by the `model` variable (use the `group_by` function).\n",
    "1. Calculate the variance of income over the variance of your predictions for each model using the \"grouped\" data from the step above (use `summarize(r_squared = var(.pred) / var(income))`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "962ac82c-48a1-424e-90a7-f6fdc71d52fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'hate_crimes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'hate_crimes' not found\nTraceback:\n",
      "1. list2(...)",
      "2. hate_crimes %>% mutate(model = \"Parallel Slopes\", .pred = predict(ps_mod, \n .     new_data = hate_crimes)$.pred)",
      "3. mutate(., model = \"Parallel Slopes\", .pred = predict(ps_mod, \n .     new_data = hate_crimes)$.pred)",
      "4. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'hate_crimes' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "\n",
    "model_results <- bind_rows(\n",
    "  hate_crimes %>% \n",
    "    mutate(model = \"Parallel Slopes\", .pred = predict(ps_mod, new_data = hate_crimes)$.pred),\n",
    "  hate_crimes %>% \n",
    "    mutate(model = \"Non-Parallel Slopes\", .pred = predict(nps_mod, new_data = hate_crimes)$.pred)\n",
    ")\n",
    "\n",
    "model_results %>%\n",
    "  group_by(model) %>%\n",
    "  summarize(r_squared = var(.pred) / var(income))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b7b72-84b9-4577-ac88-13a82f90f808",
   "metadata": {},
   "source": [
    "ðŸŽ¶ Note: you can also use the `glance` function with a model as input to find the coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c3db16-e926-46d6-8647-4277560d2e25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: object 'ps_mod' not found\n",
     "output_type": "error",
     "traceback": [
      "Error: object 'ps_mod' not found\nTraceback:\n",
      "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = NULL)\n . }, \"object 'ps_mod' not found\", base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "glance(ps_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34c756-4110-41a5-889c-102a51920a41",
   "metadata": {},
   "source": [
    "â“Compare the adjusted proportion of variance accounted for in each model. Based on this comparison, which model do you prefer? Why? \n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a249f3ee-3f67-4cfe-858c-ae5d3134035f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I preder the non parallel slopes model because it has better explanations for variations in income.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b4c84-898f-4914-b06b-2eeb99f0d234",
   "metadata": {},
   "source": [
    "â“Using your preferred model, based on your regression model parameters (and the data visualizations), is `income` greater in states that have lower or higher levels of `urbanization`? By how much?\n",
    "\n",
    "**Hint:** use the `tidy` function with your model as input to access the parameters in a nice table.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c094d0a2-2030-45a8-9643-9c6eac642fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Income is lower in states with higher urbanization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c7cba-28b1-41e4-800b-275d0895ceff",
   "metadata": {},
   "source": [
    "â“For every one percentage point increase of high-school educated adults in a state (`hs` variable), what is the associated average increase in `income`?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f5e5a71-930e-477d-98b8-a3f5e47df91c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#It would be 1%, I think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69522c5a-e9ba-4510-b1c3-ecafa85824b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-data730:R",
   "language": "R",
   "name": "conda-env-.conda-data730-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
